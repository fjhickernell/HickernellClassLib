# Confidence Intervals

If

- $\theta$ is a parameter of interest of a distribution, and

- $X_1, \ldots, X_n$ are data that we assume are collected from that distribution,

then we try to construct random quantities $\Theta_L$ and/or $\Theta_U$,
depending only on the data (and not on $\theta$), that give intervals which
[capture]{.alert} $\theta$ with high probability $1-\alpha$.  Depending on the situation, this means constructing

- a two-sided interval with  $\Prob(\Theta_L \le \theta \le \Theta_U) \ge 1-\alpha$, or

- a one-sided lower interval with  $\Prob(\Theta_L \le \theta) \ge 1-\alpha$, or

- a one-sided upper interval with  $\Prob(\theta \le \Theta_U) \ge 1-\alpha$

The bounds $\Theta_L$ and $\Theta_U$ are random because they depend on random data. Here $\alpha$ is our willingness to be wrong, typically $\alpha = 5\%$.

- In many continuous cases, the probability is exactly $1-\alpha$
- For discrete distributions, the probability is often slightly larger than $1-\alpha$

---

- [Critical value notation](#critical-value-notation-important)
- [Large sample size confidence intervals for means](#large-sample-confidence-intervals-for-means)
- [Small sample size confidence intervals for means when the distribution is known](#small-sample-confidence-intervals-for-means-when-the-distribution-is-known)
- [Confidence intervals for means of differences](#confidence-intervals-for-means-of-differences)
- [Confidence intervals for proportions](#confidence-intervals-for-proportions)
- [Confidence intervals for variances](#confidence-intervals-for-variances)


## Upper critical values{#critical-value-notation-important}

For a distribution with CDF $F$ and quantile function $Q$, define the upper critical value
$$
c_{\alpha} := Q(1-\alpha),  \quad \text{i.e., } F(c_{\alpha}) \ge 1-\alpha \text{ and } F(c_{\alpha} - \epsilon) < 1-\alpha \; \forall \epsilon > 0
$$

:::: {.columns}
::: {.column width="60%"}

Examples 

- $z_{\alpha} = Q_{\Norm(0,1)}(1-\alpha)$  
- $t_{\nu,\alpha} = Q_{t_\nu}(1-\alpha)$  
- $\chi^2_{\nu,\alpha} = Q_{\chi^2_\nu}(1-\alpha)$  

These [upper critical values]{.alert} are *not* $\alpha$-quantiles.

:::

::: {.column width="40%"}

```{python}
#| echo: false
#| fig-width: 4.8
#| fig-height: 3.6

import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st
plt.rcParams["mathtext.fontset"] = "cm"

alpha = 0.025
z = st.norm.ppf(1 - alpha)

x = np.linspace(-4, 4, 800)
y = st.norm.pdf(x)
y_z = st.norm.pdf(z)

fig, ax = plt.subplots()

# Density
ax.plot(x, y, linewidth=4)

# Critical value line: ONLY up to the pdf
ax.vlines(z, 0, y_z, linestyle="-", linewidth=4, color="tab:orange")

# Upper tail shading
xtail = x[x >= z]
ytail = st.norm.pdf(xtail)
ax.fill_between(xtail, 0, ytail, alpha=0.3, color="tab:orange")

# Title
ax.set_title(rf"Upper tail area $\alpha = {alpha} = {100*alpha}\%$", fontsize=24)

# Clean y-axis
ax.set_yticks([])

# Emphasize x-axis ticks
ax.tick_params(axis="x", labelsize=18)

# Mark z_alpha under the x-axis
ax.annotate(
    r"$z_{0.025}$",
    xy=(z, 0),
    xycoords=("data", "axes fraction"),
    xytext=(0, -18),
    textcoords="offset points",
    ha="center",
    va="top",
    fontsize=24
)

# Small tick at z_alpha
ax.plot([z, z], [0, -0.1],  linewidth=3, transform=ax.get_xaxis_transform(), color="tab:orange", 
        clip_on=False, solid_capstyle="butt")

plt.tight_layout()
plt.show()
```

:::

::::


## Large sample size confidence intervals for means{#large-sample-confidence-intervals-for-means}   
If $X_1, \ldots, X_n$ are IID with mean $\mu$ and variance $\sigma^2 < \infty$, and $\barX_n$ is the sample mean, then by the [Central Limit Theorem](../slides/01-intro.html#clt)
$$
\frac{\barX_n - \mu}{\sigma/\sqrt{n}} \appxsim \Norm(0,1) \quad \text{for large } n
$$
Letting $z_{\alpha/2}$ be the upper $\alpha/2$ quantile of $\Norm(0,1)$, i.e., $z_{\alpha/2} = Q_{\Norm(0,1)}(1 - \alpha/2)$, then
\begin{align*}
1 - \alpha & \approx
\Prob \biggl( -z_{\alpha/2} \le \frac{\barX_n - \mu}{\sigma/\sqrt{n}} \le z_{\alpha/2} \biggr) \\
& \approx \Prob \biggl( \barX_n - z_{\alpha/2} \frac{\sigma}{\sqrt{n}} \le \mu \le \barX_n + z_{\alpha/2} \frac{\sigma}{\sqrt{n}} \biggr) \\
& \approx \Prob \biggl( \underbrace{\barX_n - z_{\alpha/2} \frac{S_n}{\sqrt{n}}}_{\Theta_L} \le \mu \le \underbrace{\barX_n + z_{\alpha/2} \frac{S_n}{\sqrt{n}}}_{\Theta_U} \biggr)
\end{align*}
where $S_n^2$ is some estimate of the unknown population variance $\sigma^2$ (e.g., unbiased or MLE)

---

See the [Approval Ratings](../slides/01-intro.html#approval-ratings) example for an illustration of this construction for a Bernoulli mean

```{python}

#| echo: false
#| output: asis

import math
import scipy.stats as st

# =========================
# Parameters (edit HERE)
# =========================
n_small = 16
n_large = 400

xbar = 12.0
alpha = 0.05

# =========================
# CI helpers
# =========================

def ci_exp_exact_mu(n, xbar, alpha=0.05):
    """Exact CI for Exp mean via chi-square."""
    df = 2*n
    q_lo = st.chi2.ppf(alpha/2, df)
    q_hi = st.chi2.ppf(1 - alpha/2, df)
    return (2*n*xbar)/q_hi, (2*n*xbar)/q_lo

def ci_clt_exp_mu(n, xbar, alpha=0.05):
    """
    CLT CI for Exp mean using plug-in sigma_hat = xbar.
    """
    z = st.norm.ppf(1 - alpha/2)
    se = xbar / math.sqrt(n)
    return xbar - z*se, xbar + z*se

def fmt_ci(lo, hi, digits=2):
    return f"$[{lo:.{digits}f},\\,{hi:.{digits}f}]$"

print(
    f"_Example_: You observe $\\barX_n = {xbar}$ minutes for taxis to arrive."
    f"You construct a ${100*(1-alpha):.0f}\\%$ confidence interval for the mean arrival time, $\\mu$, assuming that the arrival times are distributed  $\\Exp(1/\\mu)$.  Recall that $\\mu = \\sigma = 1/\\lambda$.\n"
)

print("| $n$ | *CLT* CI for $\\mu$ ($S=\\barX_{n}$) | CI width |")
print("|---:|:---:|---:|")
for n in (n_small, n_large):
    lo, hi = ci_clt_exp_mu(n, xbar, alpha)
    width = hi - lo
    print(f"| {n} | {fmt_ci(lo, hi)} | {width:.3f} |")

```

---

## Small sample size confidence intervals for means when the distribution is known{#small-sample-confidence-intervals-for-means-when-the-distribution-is-known}

If the sample size is not large enough for the [Central Limit Theorem](../slides/01-intro.html#clt) to apply, but the sample mean has a known distribution, then exact confidence intervals can sometimes be constructed

```{python}
#| echo: false
#| output: asis

print(
    f"_Example_: You observe $\\barX_n = {xbar}$ minutes for taxis to arrive."
    f"based on $n$ observations. You construct a ${100*(1-alpha):.0f}\\%$ confidence interval for the mean arrival time, $\\mu$, assuming that the arrival times are distributed  $\\Exp(1/\\mu)$.  Recall that $\\mu = \\sigma = 1/\\lambda$. \n \n But now we have the true distribution of $\\barX_n$:"
)
```

::: {.columns}

::: {.column width="60%"}

\begin{align*}
2 \lambda n \barX_n &\sim \chi^2_{2n}  \\
\implies 1 - \alpha
&= \Prob \biggl( \chi^2_{2n, \alpha/2} \le 2 \lambda n \barX_n \le \chi^2_{2n, 1-\alpha/2} \biggr) \\
&= \Prob \biggl( \frac{\chi^2_{2n, \alpha/2}}{2 n \barX_n} \le \lambda \le \frac{\chi^2_{2n, 1-\alpha/2}}{2 n \barX_n} \biggr) \\
&= \Prob \biggl( \frac{2 n \barX_n}{\chi^2_{2n, 1-\alpha/2}} \le \mu \le \frac{2 n \barX_n}{\chi^2_{2n, \alpha/2}} \biggr).
\end{align*}

:::

::: {.column width="40%"}

```{python}
#| echo: false
#| fig-width: 4.8
#| fig-height: 3.4

import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st
plt.rcParams["mathtext.fontset"] = "cm"

n_plot = n_small
df = 2*n_plot
a2 = alpha/2

q_lo = st.chi2.ppf(a2, df)
q_hi = st.chi2.ppf(1 - a2, df)

c = 2*n_plot*xbar
mu_lo = c / q_hi
mu_hi = c / q_lo

# Change of variables: if Y ~ chi2_df and M = c/Y,
# then f_M(m) = f_Y(c/m) * (c/m^2)
def f_mu(mu):
    y = c/mu
    return st.chi2.pdf(y, df) * (c/(mu**2))

mu = np.linspace(0.6*mu_lo, 1.4*mu_hi, 900)
pdf = f_mu(mu)

fig, ax = plt.subplots()

# Density on mu-scale
ax.plot(mu, pdf, linewidth=4)

# Shade the CI region (blue)
mu_mid = mu[(mu >= mu_lo) & (mu <= mu_hi)]
ax.fill_between(mu_mid, 0, f_mu(mu_mid), alpha=0.3, color="tab:blue")

# Solid vertical lines at CI endpoints (blue) up to the curve
ax.vlines([mu_lo, mu_hi],
          0,
          [f_mu(mu_lo), f_mu(mu_hi)],
          linewidth=4,
          color="tab:blue")

# Label xbar under the axis
ax.annotate(
    rf"$\overline{{X}} = {xbar}$",
    xy=(xbar, 0),
    xycoords=("data", "axes fraction"),
    xytext=(0, -20),
    textcoords="offset points",
    ha="center",
    va="top",
    fontsize=18
)

ax.plot([xbar, xbar],
        [0, -0.05],
        transform=ax.get_xaxis_transform(),
        color="black",
        linewidth=2,
        clip_on=False)

ax.set_title(rf"Exact CI for $\mu$ via $\chi^2_{{{df}}}$ (central {100*(1-alpha):.0f}\%)", fontsize=24)
ax.set_yticks([])
ax.tick_params(axis="x", labelsize=18)

plt.tight_layout()
plt.show()
```

:::

:::

---
```{python}
#| echo: false
#| output: asis

print("| $n$ | *Exact* $\\chi^2$ CI | *Exact* CI width | *CLT* CI | *CLT* CI width | (CLT width/<br>Exact width) |")
print("|-:|:---:|----:|:---:|----:|-----:|")

for n in (n_small, n_large):
    clt_lo, clt_hi = ci_clt_exp_mu(n, xbar, alpha)
    ex_lo, ex_hi   = ci_exp_exact_mu(n, xbar, alpha)

    w_clt = clt_hi - clt_lo
    w_ex  = ex_hi - ex_lo

    print(
        f"| {n} | {fmt_ci(ex_lo, ex_hi)} | {w_ex:.3f} | "
        f"{fmt_ci(clt_lo, clt_hi)} | {w_clt:.3f} | {w_clt/w_ex:.3f} |"
    )
```
::: {.columns}

::: {.column width="45%"}

- For small $n$
  - Exact confidence interval can be substantially different from the CLT-based interval
  - CLT interval is symmetric about $\bar X_n$, while the exact interval is not
- As $n$ increases
  - CLT-based interval approaches the exact interval

:::

::: {.column width="55%"}

```{python}
#| echo: false
#| fig-width: 6.8
#| fig-height: 3.4

import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st
plt.rcParams["mathtext.fontset"] = "cm"

n = 16
df = 2*n

mu_hat = xbar
sigma_hat = mu_hat
se_hat = sigma_hat/np.sqrt(n)

# exact pdf of Xbar from chi-square transform:
# if Y ~ chi2_{2n} and Xbar = (mu/(2n)) Y, then
# f_Xbar(x) = f_Y( (2n/mu) x ) * (2n/mu)
def pdf_xbar_exact(x):
    y = (2*n/mu_hat)*x
    return st.chi2.pdf(y, df) * (2*n/mu_hat)

def pdf_xbar_clt(x):
    return st.norm.pdf(x, loc=mu_hat, scale=se_hat)

x_lo = max(0.0, mu_hat - 4*se_hat)
x_hi = mu_hat + 4*se_hat
x = np.linspace(x_lo, x_hi, 900)
# Central 95% regions
a2 = alpha/2

# Exact quantiles via chi-square inversion
q_lo = st.chi2.ppf(a2, df)
q_hi = st.chi2.ppf(1 - a2, df)
x_ex_lo = (mu_hat/(2*n)) * q_lo
x_ex_hi = (mu_hat/(2*n)) * q_hi

# CLT quantiles
x_clt_lo = mu_hat - st.norm.ppf(1 - a2)*se_hat
x_clt_hi = mu_hat + st.norm.ppf(1 - a2)*se_hat

fig, ax = plt.subplots()

# Exact (blue) and CLT normal (orange)
ax.plot(x, pdf_xbar_exact(x), linewidth=4, color="tab:blue")
ax.plot(x, pdf_xbar_clt(x),   linewidth=4, color="tab:orange")

# Shade exact 95% region (blue)
x_mid_ex = x[(x >= x_ex_lo) & (x <= x_ex_hi)]
ax.fill_between(x_mid_ex, 0, pdf_xbar_exact(x_mid_ex),
                color="tab:blue", alpha=0.25)

# Shade CLT 95% region (orange)
x_mid_clt = x[(x >= x_clt_lo) & (x <= x_clt_hi)]
ax.fill_between(x_mid_clt, 0, pdf_xbar_clt(x_mid_clt),
                color="tab:orange", alpha=0.25)

# Exact CI endpoints (blue)
ax.vlines([x_ex_lo, x_ex_hi],
          0,
          [pdf_xbar_exact(x_ex_lo), pdf_xbar_exact(x_ex_hi)],
          linewidth=3,
          color="tab:blue")

# CLT CI endpoints (orange)
ax.vlines([x_clt_lo, x_clt_hi],
          0,
          [pdf_xbar_clt(x_clt_lo), pdf_xbar_clt(x_clt_hi)],
          linewidth=3,
          color="tab:orange")
          
# Label xbar under the axis
ax.annotate(
    rf"$\overline{{X}} = {xbar}$",
    xy=(xbar, 0),
    xycoords=("data", "axes fraction"),
    xytext=(0, -20),
    textcoords="offset points",
    ha="center",
    va="top",
    fontsize=18
)

ax.plot([xbar, xbar],
        [0, -0.05],
        transform=ax.get_xaxis_transform(),
        color="black",
        linewidth=2,
        clip_on=False)

ax.set_title(rf"Exact vs CLT CI for $\mu$ ($n=16$, central {100*(1-alpha):.0f}\%)", fontsize=24)
ax.set_yticks([])
ax.tick_params(axis="x", labelsize=18)

# Simple legend
ax.plot([], [], linewidth=4, color="tab:blue", label="Exact (via $\\chi^2$)")
ax.plot([], [], linewidth=4, color="tab:orange",   label="CLT Normal")
ax.legend(frameon=False, fontsize=16, loc="upper right")

plt.tight_layout()
plt.show()
```

:::

::: 

&nbsp;

<a class="button" style="margin-left:0em;" href="../classlib/classlib/notebooks/confidence_interval_exact_vs_clt_vs_bootstrap.ipynb" download>
â¬‡ Exact vs CLT vs Bootstrap Confidence Interval Coverage ðŸ““
</a>

---

## Example: CI for a binomial proportion when no failures are observed{#ci-binomial-zero-failures}

You draw $n$ IID samples of your product to test for _failure_, and none of the samples fail.
What is your confidence interval for $p$, the probability that a product is satisfactory?

Let $X_i = 1$ if the $i$th product is satisfactory and $0$ otherwise. Note that
\begin{gather*}
X_i =
\begin{cases}
1, & \text{satisfactory},\\
0, & \text{failure},
\end{cases}
\qquad
X_i \sim \Bern(p), \quad p=\Prob(\text{satisfactory}),
\\
T := \sum_{i=1}^n X_i \quad \text{(\# satisfactory)} \sim \Bin(n,p).
\end{gather*}

- Want a one-sided confidence interval for $p$ of the form $[P_L,1]$; confidence in our product quality

- $P_L$ is *a random variable*, defined as a function of $T$
  - If true success probability $< P_L$, then observing $\ge T$ successes is quite unlikely

- We define a function $p_{L,\alpha} : \{0,1,\ldots,n\} \to [0,1]$ implicitly by requiring that 
$$
\Prob_{\Bin(n,p_{L,\alpha}(t))}\bigl(T \ge t\bigr) = \alpha \qquad \forall t \in \{0,1,\ldots,n\}
$$
The random lower confidence limit is then $P_L := p_{L,\alpha}(T)$

---

$[P_L,1]$ takes the form $P_L := p_{L,\alpha}(T)$, with
$$
\Prob_{\Bin(n,p_{L,\alpha}(t))}\bigl(T \ge t\bigr) = \alpha \qquad \forall t \in \{0,1,\ldots,n\}.
$$
In our case the realized confidence interval based on $n$ successes is $[p_{L,\alpha}(n),1]$, so 
$$
[p_{L,\alpha}(n)]^n = \Prob_{\Bin(n,p_{L,\alpha}(n))}\bigl(T \ge n\bigr) = \alpha \iff p_{L,\alpha}(n) = \alpha^{1/n}
$$

&nbsp;

```{python}
#| echo: false
#| output: asis

alpha = 0.05
ns = [5, 10,20, 100]
vals = [alpha**(1/n) for n in ns]

print("| $n$ | " + " | ".join(str(n) for n in ns) + " |")
print("|:-:|" + "|".join(["---"]*len(ns)) + "|")
print("| $p_L = \\alpha^{1/n}$ | " + " | ".join(f"{v:.4f}" for v in vals) + " |")

```


## Confidence Intervals for _Means_ of Differences

For paired or matched data (before/after, twins, same subject measured twice)
$$
D_i = X_i - Y_i, \quad i = 1,\dots,n
$$

Inference is about the **mean difference** $\mu_D$ (paired setting)

_Not_ difference of means $\mu_X - \mu_Y$ (unpaired), even though $\barD_n= \barX_n - \barY_n$

If $D_1,\dots,D_n \IIDsim \Norm(\mu_D, \sigma_D^2)$
$$
\Prob\left[ \barD_n - t_{n-1,\alpha/2}\frac{S_{D,n}}{\sqrt{n}} \le \mu_D \le \barD_n  + t_{n-1,\alpha/2}\frac{S_{D,n}}{\sqrt{n}} \right] = 1 - \alpha
$$
where $\displaystyle S_{D,n}^2 = \frac 1{n-1} \sum_{i=1}^n (D_i - \barD_n)^2$

If $D_1,\dots,D_n$ are IID with finite variance, and $n$ is large
$$
\Prob\left[ \barD_n - z_{\alpha/2}\frac{S_{D,n}}{\sqrt{n}} \le \mu_D \le \barD_n + z_{\alpha/2}\frac{S_{D,n}}{\sqrt{n}} \right] \approx 1 - \alpha
$$


## Confidence Intervals for _Differences_ of Means

For two _independent_ samples (control/treatment, two groups)

$$
X_1,\dots,X_{n_X} \sim \text{population 1}, \quad
Y_1,\dots,Y_{n_Y} \sim \text{population 2}
$$

with sample means $\barX_{n_X}, \barY_{n_Y}$ and sample variances
$S_{X,n_X}^2, S_{Y,n_Y}^2$

---

### Pooled-$t$ confidence interval (Wackerly)

Assume that the two populations:

- Are sampled [independently]{.alert}
- Are [Normal]{.alert} 
- Have a [common variance]{.alert} $\sigma^2$

Define the _pooled variance_ estimator of $\sigma^2$ as
$$
S_p^2
=
\frac{(n_X-1)S_{X,n_X}^2 + (n_Y-1)S_{Y,n_Y}^2}{n_X + n_Y - 2}.
$$

Then a $t$-based confidence interval for $\mu_X - \mu_Y$ is

\begin{multline*}
\Prob\left[
(\barX_{n_X}-\barY_{n_Y})
-
t_{n_X+n_Y-2,\alpha/2}
\, S_p
\sqrt{\frac{1}{n_X} + \frac{1}{n_Y}}
\le \mu_X - \mu_Y \right .  \\ \left .
\le
(\barX_{n_X}-\barY_{n_Y})
+
t_{n_X+n_Y-2,\alpha/2}
\, S_p
\sqrt{\frac{1}{n_X} + \frac{1}{n_Y}}
\right]
=
1 - \alpha.
\end{multline*}

---

Other variations exist (Welch two-sample $t$, unequal variances).


### CLT-based interval (large samples)

If $n_X$ and $n_Y$ are large and the samples are independent, then a
_CLT-based confidence interval_ applies even if the two populations:

- need _not_ be Normal
- need _not_ have a common variance

\begin{multline*}
\Prob\left[
(\barX_{n_X}-\barY_{n_Y})
-
z_{\alpha/2}
\sqrt{\frac{S_{X,n_X}^2}{n_X}+\frac{S_{Y,n_Y}^2}{n_Y}}
\le \mu_X - \mu_Y \right . \\ \left .
\le
(\barX_{n_X}-\barY_{n_Y})
+
z_{\alpha/2}
\sqrt{\frac{S_{X,n_X}^2}{n_X}+\frac{S_{Y,n_Y}^2}{n_Y}}
\right]
\approx
1 - \alpha.
\end{multline*}

## Confidence Interval for _Proportions_ (CLT) {#confidence-intervals-for-proportions}

### One proportion
- $X_1,\dots,X_n \IIDsim \Bern(p)$  ($p =$ probability of success shooting free throws, product quality control, etc.)
- $\hP_n = \frac{1}{n}\sum_{i=1}^n X_i =$ sample proportion of successes
- $\Ex[\hP_n] = p$ and $\var(\hP_n) = p(1-p)/n$

If $n$ is large, an [approximate CLT-based]{.alert} interval for $p$ is

\begin{equation*}
\Prob\left[
\hP_n
-
z_{\alpha/2}\sqrt{\frac{\hP_n(1-\hP_n)}{n}}
\le p 
\le
\hP_n
+
z_{\alpha/2}\sqrt{\frac{\hP_n(1-\hP_n)}{n}}
\right]
\approx
1-\alpha
\end{equation*}

---

### Difference of two proportions

[Independent]{.alert} samples 
\begin{gather*}
X_1,\dots,X_{n_X} \IIDsim \Bern(p_X), \qquad
Y_1,\dots,Y_{n_Y} \IIDsim \Bern(p_Y)
\\
\hP_X = \frac{1}{n_X}\sum X_i,
\qquad
\hP_Y = \frac{1}{n_Y}\sum Y_j
\end{gather*}

If $n_X$ and $n_Y$ are large, an [approximate CLT-based]{.alert} confidence interval for $p_X - p_Y$ is

\begin{multline*}
\Prob\left[
(\hP_X-\hP_Y)
-
z_{\alpha/2}
\sqrt{\frac{\hP_X(1-\hP_X)}{n_X}
+
\frac{\hP_Y(1-\hP_Y)}{n_Y}}
\right . \\ \left .
\le p_X - p_Y \le
(\hP_X-\hP_Y)
+
z_{\alpha/2}
\sqrt{\frac{\hP_X(1-\hP_X)}{n_X}
+
\frac{\hP_Y(1-\hP_Y)}{n_Y}}
\right]
\approx
1-\alpha
\end{multline*}

## Confidence Interval for a _Variance_

Let $X_1,\dots,X_n \IIDsim \Norm(\mu,\sigma^2)$  with sample variance $S_n^2$

Then
$$
\frac{(n-1)S_n^2}{\sigma^2} \sim \chi^2_{n-1}
$$

and a $(1-\alpha)$ confidence interval for $\sigma^2$ is

\begin{equation*}
\Prob\left[
\frac{(n-1)S_n^2}{\chi^2_{n-1,\,1-\alpha/2}}
\le \sigma^2 \le
\frac{(n-1)S_n^2}{\chi^2_{n-1,\,\alpha/2}}
\right]
=
1-\alpha
\end{equation*}

## Confidence Interval for _Ratio_ of Variances

Let
$$
X_1,\dots,X_{n_X} \IIDsim \Norm(\mu_X,\sigma_X^2), \quad
Y_1,\dots,Y_{n_Y} \IIDsim \Norm(\mu_Y,\sigma_Y^2)
$$

be  independent samples with sample variances
$S_{X,n_X}^2, S_{Y,n_Y}^2$, respectively

Then
$$
\frac{S_{X,n_X}^2 / \sigma_X^2}{S_{Y,n_Y}^2 / \sigma_Y^2}
\sim
F_{\,n_X-1,n_Y-1}
$$

and a $(1-\alpha)$ confidence interval for
$\displaystyle \frac{\sigma_X^2}{\sigma_Y^2}$ is

\begin{equation*}
\Prob\left[
\frac{S_{X,n_X}^2}{S_{Y,n_Y}^2}
\frac{1}{F_{n_X-1,n_Y-1;\,1-\alpha/2}}
\le
\frac{\sigma_X^2}{\sigma_Y^2}
\le
\frac{S_{X,n_X}^2}{S_{Y,n_Y}^2}
\frac{1}{F_{n_X-1,n_Y-1;\,\alpha/2}}
\right]
=
1-\alpha
\end{equation*}

## Bootstrap Confidence Intervals{#bootstrap-confidence-intervals}

Classical confidence intervals rely on assumptions such as:

- Known or estimable variance
- Normality of the sampling distribution
- Large sample sizes (via CLT)

But in practice we often have:

- Small samples
- Skewed or heavy-tailed data
- Complicated estimators (medians, quantiles, ratios)

*Bootstrap confidence intervals* replace distributional assumptions with
[resampling from the observed data]{.alert} to approximate the sampling distribution of an estimator


## The Bootstrap Idea

Given data $X_1,\dots,X_n$ and an estimator $\Theta$:

1. Resample _with replacement_ from the data to form $B$ bootstrap samples  
   Each bootstrap sample has size $n$ and consists of draws from the original data
   $$
   X_1^{(b)},\dots,X_n^{(b)} \IIDsim \text{Uniform}\{X_1,\dots,X_n\}, \quad b=1,\dots,B
   $$
2. Compute the bootstrap estimators $\Theta^{(b)}$
    $$
    \Theta^{(b)} = \Theta(X_1^{(b)},\dots,X_n^{(b)}), \quad b=1,\dots,B
    $$

3. Use the empirical distribution of $\Theta^{(1)},\dots,\Theta^{(B)}$ to construct confidence intervals

A simple *bootstrap percentile CI* uses the _order statistics_ of the bootstrap estimators:
$$
\left[
\Theta_{(\alpha/2)},
\Theta_{(1-\alpha/2)}
\right]
$$

> No normality Â· No variance formula Â· Works when classical assumptions fail

---

<a class="button" style="margin-left:0em;" href="../classlib/classlib/notebooks/confidence_interval_exact_vs_clt_vs_bootstrap.ipynb" download>
â¬‡ Exact vs CLT vs Bootstrap Confidence Interval Coverage ðŸ““
</a>

## Example of vanilla bootstrap

```{python}
#| echo: false
#| output: asis

import numpy as np
import pandas as pd

# population generator (same as notebook)
def generate_population(N):
    return np.random.exponential(scale=2.0, size=N)

# draw original sample
n = 8 # sample size

print(f"""
We draw a _single IID random sample of size_ $n={n}$ from a population:
$$
X_1,\\dots,X_{{{n}}}, \\qquad 
\\barX = \\frac{{1}}{{{n}}}\\sum_{{i=1}}^{{{n}}} X_i
$$
A *vanilla bootstrap sample* is obtained by sampling **with replacement**
from the observed data $\\{{X_1,\\dots,X_{{{n}}}\\}}$.  We repeat this independently to obtain _bootstrap_ samples.
""")

# population generator (same as notebook)
def generate_population(N):
    return np.random.exponential(scale=2.0, size=N)

# draw original sample
N = 10_000 #population size
population = generate_population(N)
sample = np.random.choice(population, size=n, replace=False)

# bootstrap samples
B = 4
boot_samples = np.random.choice(sample, size=(B, n), replace=True)

# ---------- helpers ----------

def fmt_sample(x):
    return ", ".join(f"{xi:.2f}" for xi in x)

def print_md_table(header, rows):
    print('<table style="width:100%; table-layout:fixed;">')
    print("<thead><tr>")
    print(f'<th style="width:20%;">{header[0]}</th>')
    print(f'<th style="width:55%;">{header[1]}</th>')
    print(f'<th style="width:25%;">{header[2]}</th>')
    print("</tr></thead>")
    print("<tbody>")
    for c1, c2, c3 in rows:
        print("<tr>")
        print(f"<td>{c1}</td>")
        print(f"<td>{c2}</td>")
        print(f"<td>{c3}</td>")
        print("</tr>")
    print("</tbody></table>")

# ---------- build rows ----------

rows = []
rows.append(("**Original**", fmt_sample(sample), sample.mean()))

for b in range(B):
    rows.append(
        (f"Bootstrap {b+1}", fmt_sample(boot_samples[b]), boot_samples[b].mean())
    )

# add vdots row
rows.append((
    r"$\vdots$",
    r"$\vdots$",
    r"$\vdots$"
))

# ---------- print markdown table ----------

header = ["Sample", "Observations", "Sample mean"]

md_rows = []
for name, obs, m in rows:
    md_rows.append([
        name,
        obs,
        f"{m:.2f}" if isinstance(m, (int, float)) else m
    ])

print_md_table(header, md_rows)

```

## Assumptions behind common confidence intervals

Data are IID from a distribution with finite variance

| Parameter | Distributional Assumptions | Sample Size | Method | Notes |
|-------|--------------------------------|--------|-----------------------|----------------------------|
| $\mu$ | **Any** distribution | **Large** $n$ | **CLT** | **Approximate**, accuracy improves as $n \to \infty$ |
| $\mu$ |  **Normal** data, <br>$\sigma$ unknown | Any $n$ | Studentâ€™s *t* | **Exact**|
| $\mu = p$ | **Bernoulli** trials | Any $n$ | Binomial<br>(Clopperâ€“Pearson) | **Exact**<br>Conservative |
| $\mu = p$ | **Bernoulli** trials | Large $np$,  $n(1-p)$ | **CLT** | **Approximate** |
| $\mu$ | **Exponential** data | Any $n$ | Gamma/<br>Chi-squared  | **Exact** |

---

| Parameter | Distributional Assumptions | Sample Size | Method | Notes |
|-------|--------------------------------|--------|-----------------------|----------------------------|
| $\mu_D$ <br>(paired differences)| Differences are **Normal** | Any $n$ | Paired *t* |  **Exact**, sometimes confused with two-sample *t* |
| $\mu_X-\mu_Y$ | Each sample **Normal**; independent samples; **common variance** | Any $n_X,n_Y$ | Two-sample *t* (pooled) | **Exact** |
| $\mu_X-\mu_Y$  | Independent samples from **any** distributions with finite variances | **Large** $n_X,n_Y$ | **CLT** (two-sample) | **Approximate**|
| $p_X-p_Y$ | Independent samples of **Bernoulli** trials | Large $n_Xp_X$, $n_X(1-p_X)$, $n_Yp_Y$, $n_Y(1-p_Y)$ | **CLT** (two-sample) | **Approximate** |


---

| Parameter | Distributional Assumptions | Sample Size | Method | Notes |
|-------|--------------------------------|--------|-----------------------|----------------------------|
| $\sigma^2$ | **Normal** data | Any $n$ | Chi-squared | **Exact**, sensitive to non-normality |
| $\sigma_X^2/\sigma_Y^2$ | **Normal** data; independent samples | Any $n_X,n_Y$ | F-distribution | **Exact**, sensitive to non-normality |
| $\med(F)$ | Continuous distribution | $n$ not too small | Order-statistics |**Approximate**, Distribution-free |  
| $\theta(F)$ | **None** (empirical distribution) | Moderate $n$ | Bootstrap resampling | **Approximate**, works when classical theory breaks |

---

### Summary

- Confidence intervals provide a [range of plausible values]{.alert} for parameters based on data
  - They go beyond point estimation by quantifying uncertainty
- Expressed in terms of random variables, confidence intervals are [probabilistic]{.alert} statements about the data-generating process
- Realized by plugging in the observed data, confidence intervals are _not_ probabilistic statements
- Validity of confidence intervals depends on assumptions about the [data distribution]{.alert} and [sample size(s)]{.alert}
  - With fewer data we need stronger distributional assumptions
  - With more data we can rely on asymptotic results like the CLT
- Two-sided CLT confidence intervals take the form 
$$\text{estimator} \pm z_{\alpha/2} \times \text{standard error}$$


